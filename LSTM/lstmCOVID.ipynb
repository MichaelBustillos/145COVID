{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_state_predictions(train, test, state, prediction):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    \n",
    "    train_data = train[prediction].values.astype(float)\n",
    "    test_data = test[prediction].values.astype(float)\n",
    "\n",
    "    train_data_normalized = scaler.fit_transform(train_data .reshape(-1, 1))\n",
    "    train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)\n",
    "    train_window = 30\n",
    "    train_inout_seq = create_inout_sequences(train_data_normalized, train_window)\n",
    "\n",
    "    model = LSTM()\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    epochs = 75\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for seq, labels in train_inout_seq:\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "            y_pred = model(seq)\n",
    "\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    fut_pred = 30\n",
    "\n",
    "    test_inputs = train_data_normalized[-train_window:].tolist()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(fut_pred):\n",
    "\n",
    "        seq = torch.FloatTensor(test_inputs[-train_window:])\n",
    "        with torch.no_grad():\n",
    "            model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "            test_inputs.append(model(seq).item())\n",
    "\n",
    "    actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:] ).reshape(-1, 1))\n",
    "    return actual_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama\n",
      "Alabama\n",
      "Alaska\n",
      "Alaska\n",
      "Arizona\n",
      "Arizona\n",
      "Arkansas\n",
      "Arkansas\n",
      "California\n",
      "California\n",
      "Colorado\n",
      "Colorado\n",
      "Connecticut\n",
      "Connecticut\n",
      "Delaware\n",
      "Delaware\n",
      "Florida\n",
      "Florida\n",
      "Georgia\n",
      "Georgia\n",
      "Hawaii\n",
      "Hawaii\n",
      "Idaho\n",
      "Idaho\n",
      "Illinois\n",
      "Illinois\n",
      "Indiana\n",
      "Indiana\n",
      "Iowa\n",
      "Iowa\n",
      "Kansas\n",
      "Kansas\n",
      "Kentucky\n",
      "Kentucky\n",
      "Louisiana\n",
      "Louisiana\n",
      "Maine\n",
      "Maine\n",
      "Maryland\n",
      "Maryland\n",
      "Massachusetts\n",
      "Massachusetts\n",
      "Michigan\n",
      "Michigan\n",
      "Minnesota\n",
      "Minnesota\n",
      "Mississippi\n",
      "Mississippi\n",
      "Missouri\n",
      "Missouri\n",
      "Montana\n",
      "Montana\n",
      "Nebraska\n",
      "Nebraska\n",
      "Nevada\n",
      "Nevada\n",
      "New Hampshire\n",
      "New Hampshire\n",
      "New Jersey\n",
      "New Jersey\n",
      "New Mexico\n",
      "New Mexico\n",
      "New York\n",
      "New York\n",
      "North Carolina\n",
      "North Carolina\n",
      "North Dakota\n",
      "North Dakota\n",
      "Ohio\n",
      "Ohio\n",
      "Oklahoma\n",
      "Oklahoma\n",
      "Oregon\n",
      "Oregon\n",
      "Pennsylvania\n",
      "Pennsylvania\n",
      "Rhode Island\n",
      "Rhode Island\n",
      "South Carolina\n",
      "South Carolina\n",
      "South Dakota\n",
      "South Dakota\n",
      "Tennessee\n",
      "Tennessee\n",
      "Texas\n",
      "Texas\n",
      "Utah\n",
      "Utah\n",
      "Vermont\n",
      "Vermont\n",
      "Virginia\n",
      "Virginia\n",
      "Washington\n",
      "Washington\n",
      "West Virginia\n",
      "West Virginia\n",
      "Wisconsin\n",
      "Wisconsin\n",
      "Wyoming\n",
      "Wyoming\n"
     ]
    }
   ],
   "source": [
    "data_tendency = pd.read_csv('train_trendency.csv')\n",
    "data_tendency['Date'] = pd.to_datetime(data_tendency['Date'], format=\"%m-%d-%Y\")\n",
    "data_tendency['Date'] = data_tendency['Date'].dt.strftime('%m-%d-%Y')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "for states in test['Province_State'].unique(): \n",
    "    test_one = test[test['Province_State'] == states]\n",
    "    test_idx = test_one.set_index([\"Date\"], drop=True)\n",
    "    test_idx = test_idx.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    data_one = data_tendency[data_tendency['Province_State'] == states]\n",
    "    df_idx = data_one.set_index([\"Date\"], drop=True)\n",
    "    \n",
    "    print(states)\n",
    "    predictions = make_state_predictions(df_idx, test_idx, states, 'Deaths')\n",
    "\n",
    "    flat_list = [item for sublist in predictions for item in sublist]\n",
    "    test[test['Province_State'] == states]['Deaths']\n",
    "    state_indices = test[test['Province_State'] == states]['Unnamed: 0'].values\n",
    "    for i in state_indices:\n",
    "        test.loc[test['Unnamed: 0'] == i, 'Deaths'] = flat_list[0]\n",
    "        flat_list = flat_list[1:]\n",
    "    \n",
    "    print(states)\n",
    "    predictions = make_state_predictions(df_idx, test_idx, states, 'Confirmed')\n",
    "\n",
    "    flat_list = [item for sublist in predictions for item in sublist]\n",
    "    test[test['Province_State'] == states]['Confirmed']\n",
    "    state_indices = test[test['Province_State'] == states]['Unnamed: 0'].values\n",
    "    for i in state_indices:\n",
    "        test.loc[test['Unnamed: 0'] == i, 'Confirmed'] = flat_list[0]\n",
    "        flat_list = flat_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.139128e+05</td>\n",
       "      <td>10472.914835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.367897e+04</td>\n",
       "      <td>314.451297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.445481e+05</td>\n",
       "      <td>16782.711560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.292941e+05</td>\n",
       "      <td>5684.064695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.650360e+06</td>\n",
       "      <td>60900.534919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1495</td>\n",
       "      <td>1495</td>\n",
       "      <td>6.143826e+05</td>\n",
       "      <td>9874.587459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1496</td>\n",
       "      <td>1496</td>\n",
       "      <td>3.758915e+05</td>\n",
       "      <td>5169.913273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1.457877e+05</td>\n",
       "      <td>2666.945983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1498</td>\n",
       "      <td>1498</td>\n",
       "      <td>6.384768e+05</td>\n",
       "      <td>7267.109333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>5.722789e+04</td>\n",
       "      <td>697.200008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Unnamed: 0.1     Confirmed        Deaths\n",
       "0        0             0  5.139128e+05  10472.914835\n",
       "1        1             1  6.367897e+04    314.451297\n",
       "2        2             2  8.445481e+05  16782.711560\n",
       "3        3             3  3.292941e+05   5684.064695\n",
       "4        4             4  3.650360e+06  60900.534919\n",
       "...    ...           ...           ...           ...\n",
       "1495  1495          1495  6.143826e+05   9874.587459\n",
       "1496  1496          1496  3.758915e+05   5169.913273\n",
       "1497  1497          1497  1.457877e+05   2666.945983\n",
       "1498  1498          1498  6.384768e+05   7267.109333\n",
       "1499  1499          1499  5.722789e+04    697.200008\n",
       "\n",
       "[1500 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.to_csv('results3.csv')\n",
    "results = test.drop(\"Province_State\", axis=1)\n",
    "results = results.drop(\"Date\", axis=1)\n",
    "results.rename(columns = {'Unnamed: 0':'ID'}, inplace = True)\n",
    "results.to_csv('submit3.csv')\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
